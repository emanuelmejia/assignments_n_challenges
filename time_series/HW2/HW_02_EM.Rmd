---
title : 'W271 Assignment 2'
author: "Emanuel Mej√≠a"
output: 
  pdf_document:
    toc: true
    number_sections: true
---

```{r load packages, message=FALSE}
library(tidyverse)
library(package = car)
library(package = mcprofile)
```


# Customer churn study: **Part-2** (100 Points)

In the previous homework assignment, you began modeling a binary variable using customer churn data from a telecommunications company to analyze churn tendencies among senior and non-senior customers.

Now, in Part-2 of the homework, we will delve into regression techniques to develop a more comprehensive model for the telecom company. This model will provide insights into the reasons why customers may choose to discontinue their services.

```{r load of the data}
telcom_churn <- read.csv("./data/Telco_Customer_Churn.csv", header=T,na.strings=c("","NA")) 
```

Churn dataset consists of 21 variables and 7043 observations. The customer variables are provided below:


For the remainder of this section, pay particular attention to `Churn,` `tenure,` `MonthlyCharges,` and `TotalCharges.`

## Data Preprocessing (5 Points)

In this section, review the data structure to ensure the correct data types for variables of interest, convert variables as necessary, and address any missing values.

We can first check the type of data we have in each column:

```{r Type of Data}
sapply(telcom_churn, function(x) typeof(x))
```
Since we'll be manually doing certain computations we'll turn the Churn column to have integers instead:

```{r Convert Churn}
telcom_churn["Churn"][telcom_churn["Churn"] == "No"] <- 0
telcom_churn["Churn"][telcom_churn["Churn"] == "Yes"] <- 1

telcom_churn$Churn <- as.integer(telcom_churn$Churn)

```

We can also check the count of missing values for every column in our data:

```{r Missing Values}
sapply(telcom_churn, function(x) sum(is.na(x)))
```

We'll be using the Total Charges variable, which is the only column with missing values. Since we have enough observations we can drop the ones with NA.

```{r Drop Missing}
telcom_churn <- na.omit(telcom_churn)
```

## Maximum Likelihood (15 Points)

Let's build off of the maximum likelihood model of a binomial distribution from lecture and apply it to the churn data set.

Our objective is to estimate the probability of a customer churning based on their `tenure` with the company. While we will use logistic regression in subsequent sections, here, we will focus on the maximum likelihood approach.

Suppose that we can express the probability of a customer churning as a function of tenure in the following form (you should recognize this as the connection between log odds and probability from the lecture):

$$P(Churn)=P(\alpha,\beta)=\frac{e^{\alpha+\beta*Tenure}}{1+e^{\alpha+\beta*Tenure}}$$

Using this and assuming the number of churned customers in the data set follows a binomial distribution with parameters $n$ and $p(\alpha,\beta)$, **write down the likelihood function $L(\alpha,\beta|Data)$**.

\begin{align*}
    L(\alpha , \beta |Data) &= L(\alpha , \beta |y_1, y_2, ..., y_n)\\
    &= \prod_{i=1}^{n}\: p(\alpha, \beta)_i ^ {y_i} \left(1 - p(\alpha, \beta)_i\right) ^ {1-y_i}\\
    &= \prod_{i=1}^{n}\: \left[\left(\frac{e^{\alpha+\beta*T_i}}{1+e^{\alpha+\beta*T_i}}\right) ^ {y_i} \left(1 - \frac{e^{\alpha+\beta*T_i}}{1+e^{\alpha+\beta*T_i}}\right) ^ {1-y_i}\right]
    & \text{with } Ti = Tenure \text{ for obs } i\\
\end{align*}


## Write and compute the log-likelihood (10 Points)

Find the **negative log likelihood** and write an R function to calculate it given inputs of alpha and beta and using the churn data.

From the result above we can compute

\allowdisplaybreaks
\begin{align*}
    -log(L(\alpha , \beta |Data)) &= -log\left(\prod_{i=1}^{n}\: \left[\left(\frac{e^{\alpha+\beta*T_i}}{1+e^{\alpha+\beta*T_i}}\right) ^ {y_i} \left(1 - \frac{e^{\alpha+\beta*T_i}}{1+e^{\alpha+\beta*T_i}}\right) ^ {1-y_i}\right]\right)\\
    &= - \sum_{i=1}^{n}\: y_i log\left(\frac{e^{\alpha+\beta*T_i}}{1+e^{\alpha+\beta*T_i}}\right) + (1-y_i) log\left(1 - \frac{e^{\alpha+\beta*T_i}}{1+e^{\alpha+\beta*T_i}}\right)\\
    &= - \sum_{i=1}^{n}\: y_i log\left(\frac{e^{\alpha+\beta*T_i}}{1+e^{\alpha+\beta*T_i}}\right) + (1-y_i) log\left(\frac{1}{1+e^{\alpha+\beta*T_i}}\right)\\
    &= - \sum_{i=1}^{n}\: y_i log\left(\frac{e^{\alpha+\beta*T_i}}{1+e^{\alpha+\beta*T_i}}\right) + log\left(\frac{1}{1+e^{\alpha+\beta*T_i}}\right) - y_i log\left(\frac{1}{1+e^{\alpha+\beta*T_i}}\right)\\
    &= - \sum_{i=1}^{n}\: y_i \left[log\left(\frac{e^{\alpha+\beta*T_i}}{1+e^{\alpha+\beta*T_i}}\right)  - log\left(\frac{1}{1+e^{\alpha+\beta*T_i}}\right)\right] + log\left(\frac{1}{1+e^{\alpha+\beta*T_i}}\right)\\
    &= - \sum_{i=1}^{n}\: y_i \left[log\left(\frac{e^{\alpha+\beta*T_i}}{1+e^{\alpha+\beta*T_i}}\left(1+e^{\alpha+\beta*T_i}\right)\right)\right] + log\left(\frac{1}{1+e^{\alpha+\beta*T_i}}\right)\\
    &= - \sum_{i=1}^{n}\: y_i log\left(e^{\alpha+\beta*T_i}\right) + log\left(\frac{1}{1+e^{\alpha+\beta*T_i}}\right)\\
    &= - \sum_{i=1}^{n}\: y_i \left(\alpha+\beta*T_i\right) + log\left(\frac{1}{1+e^{\alpha+\beta*T_i}}\right)\\
    &= - \sum_{i=1}^{n}\: y_i log\left(e^{\alpha+\beta*T_i}\right) - log\left(1+e^{\alpha+\beta*T_i}\right)\\
    &= - \sum_{i=1}^{n}\: y_i \left(\alpha+\beta*T_i\right) - log\left(1+e^{\alpha+\beta*T_i}\right)\\
    &= \sum_{i=1}^{n}\: log\left(1+e^{\alpha+\beta*T_i}\right) - y_i \left(\alpha+\beta*T_i\right)\\
\end{align*}

Now if we put it in R:

```{r NegLogL}
neglogL <- function(params, x, Y){
  pi <- exp(params[1] + params[2] * x) / (1 + exp(params[1] + params[2] * x))
  -sum(Y * log(pi) + (1-Y)*log(1-pi))
}
```

## Compute the MLE of parameters (10 Points)  

Use the optim function to **find the MLE of alpha and beta on the churn data**. You can use starting values of 0 for both parameters. Note that optim by default finds the minimum, so you can use the negative log likelihood directly.

```{r Optim}
mod.fit.optim <- optim(
  par = c(0,0),
  fn = neglogL,
  hessian = T,
  x = telcom_churn$tenure,
  Y = as.numeric(telcom_churn$Churn),
  method = "BFGS"
)
```

We can test that our model indeed converged as follows:

```{r Convergence}
mod.fit.optim$convergence
```

And get the parameters:

```{r}
mod.fit.optim$par
```

So now we know:

$\hat{\alpha}$ =  `r mod.fit.optim$par[1]`

$\hat{\beta}$ = `r mod.fit.optim$par[2]`

## Calculate a confidence interval (10 Points)  

Again using the optim function, find the **variance of the MLE estimates** (hint use hessian = TRUE in optim) for alpha and beta. Calculate a **95% confidence interval** for each parameter. Are they statistically different than zero?

We first find the Var-Cov Matrix as follows:

```{r}
mod.optim.vcov <- solve(mod.fit.optim$hessian)
mod.optim.vcov
```

So we have the following variances:

$\widehat{Var}(\hat{\alpha}) =$  `r mod.optim.vcov[1,1]`

$\widehat{Var}(\hat{\beta})=$  `r mod.optim.vcov[2,2]`

And now we'll compute the following Wald confidence intervals for each parameter:

```{r Alpha CI}
alpha.wci <- mod.fit.optim$par[1] + qnorm(p = c(0.025, 0.975)) * sqrt(mod.optim.vcov[1,1])
alpha.wci
```

```{r Beta CI}
beta.wci <- mod.fit.optim$par[2] + qnorm(p = c(0.025, 0.975)) * sqrt(mod.optim.vcov[2,2])
beta.wci
```

Which means that:

- The 95% Wald confidence interval for $\alpha$ is `r round(alpha.wci[1],4)` $<\alpha<$ `r round(alpha.wci[2],4)`, so it seems that it's **not statistically different than zero** (since 0 is part of the interval). Nevertheless, this is our Intercept coefficient, so we might just use it anyways.

- The 95% Wald confidence interval for $\beta$ (tenure parameter) is `r round(beta.wci[1],4)` $<\beta<$ `r round(beta.wci[2],4)`, so it seems that is indeed **statistically different than zero** (since 0 is not part of the interval). Meaning that in a hypothesis test, we would reject a *null hypothesis* of the form $H_0 : \beta = 0$, and we would include Tenure in our model.

## Model comparison (10 Points)  

Estimate a logistic regression model with `tenure` as the independent variable. Compare **MLE of alpha and beta to the output of the logistic regression**. What do you notice? Can you think of why this is the case? (Think about the connection between MLE of regression coefficients and linear regression)

```{r LogReg}
mod.fit <- glm(
  formula = as.numeric(Churn) ~ tenure, 
  family = binomial(link = logit), 
  data = telcom_churn
)
summary(mod.fit)
```

The parameters $\alpha$ and $\beta$ are the same in both methods, the standard error and the variance are also consistent:

$\widehat{Var}(\hat{\alpha}) =$  `r mod.optim.vcov[1,1]` $\Longrightarrow SE = \sqrt{\widehat{Var}(\hat{\alpha})} =$ `r sqrt(mod.optim.vcov[1,1])`

$\widehat{Var}(\hat{\beta})=$  `r mod.optim.vcov[2,2]` $\Longrightarrow SE= \sqrt{\widehat{Var}(\hat{\beta})} =$ `r sqrt(mod.optim.vcov[2,2])`

## Extended Model, with Linear Effects (10 Points)  

Use the `Churn`, `tenure`, `MonthlyCharges`, and `TotalCharges` as  independent variables in a logistic regression model for predicting a customer churning. Proceed to estimate the model and subsequently, interpret each of the indicator variables incorporated within the model.

```{r FullMod}
mod.fit.full <- glm(
  formula = as.numeric(Churn) ~ tenure + MonthlyCharges + TotalCharges, 
  family = binomial(link = logit), 
  data = telcom_churn
)
summary(mod.fit.full)
```

So our logistic regression model is the following:

$logit(\hat{\pi}) =$ `r round(mod.fit.full$coefficients[1],4)` $+$ `r round(mod.fit.full$coefficients[2],4)` $tenure +$ `r round(mod.fit.full$coefficients[3],4)` $MonthlyCharges +$ `r format(round(mod.fit.full$coefficients[4],6),scientific = FALSE)` $TotalCharges$

Which basically means the following:

- Given that the other variables are in the model we have enough evidence that there's a negative relationship between `tenure` and $\pi$: The higher the `tenure` the lower the probability of `Churn`.
- Given that the other variables are in the model we have enough evidence that there's a positive relationship between `MonthlyCharges` and $\pi$: The higher the `MonthlyCharges` the higher the probability of `Churn`.
- Given that the other variables are in the model we have marginal evidence that there's We have a positive relationship between `TotalCharges` and $\pi$: The higher the `TotalCharges` the higher the probability of `Churn`.

## Likelihood Ratio Tests (10 Points)  

Perform likelihood ratio tests for all independent variables to evaluate their importance within the model. Discuss and interpret the results of these tests. 

We can do these tests with one of two methods, the first one is by using the Anova function as follows:

```{r Anova}
Anova.tests <- Anova(mod.fit.full, test = "LR")
LR.chisq <- Anova.tests[["LR Chisq"]]
p.val.chisq <- Anova.tests[["Pr(>Chisq)"]]
Anova.tests
```

The second one is by computing them through the "anova" function. Atlhough we need to do it one by one, as follows:

```{r anova}
mod.fit.H0_ten <- glm(
  formula = as.numeric(Churn) ~ MonthlyCharges + TotalCharges, 
  family = binomial(link = logit), 
  data = telcom_churn
)

mod.fit.H0_Mon <- glm(
  formula = as.numeric(Churn) ~ tenure + TotalCharges, 
  family = binomial(link = logit), 
  data = telcom_churn
)

mod.fit.H0_Tot <- glm(
  formula = as.numeric(Churn) ~ tenure + MonthlyCharges, 
  family = binomial(link = logit), 
  data = telcom_churn
)
```

```{r}
anova(mod.fit.H0_ten, mod.fit.full, test = "Chisq")
anova(mod.fit.H0_Mon, mod.fit.full, test = "Chisq")
anova(mod.fit.H0_Tot, mod.fit.full, test = "Chisq")
```

These results are consistent with the ones obtained in question 1.7:

- For the test of `tenure` with $H_0: \beta_1 = 0$ VS $H_a: \beta_1 \ne 0$ we obtain $-2log(\Delta) =$ `r round(LR.chisq[1],4)` and a p-value of $\mathbb{P}(A>$ `r round(LR.chisq[1],4)` $)=$ `r p.val.chisq[1]` meaning that we have enough evidence that `tenure` is important to include in the model (given that the other variables are in the model as well).
- For the test of `MonthlyCharges` with $H_0: \beta_2 = 0$ VS $H_a: \beta_2 \ne 0$ we obtain $-2log(\Delta) =$ `r round(LR.chisq[2],4)` and a p-value of $\mathbb{P}(A>$ `r round(LR.chisq[2],4)` $)=$ `r p.val.chisq[2]` meaning that we have enough evidence that `MonthlyCharges` is important to include in the model (given that the other variables are in the model as well).
- For the test of `TotalCharges` with $H_0: \beta_3 = 0$ VS $H_a: \beta_3 \ne 0$ we obtain $-2log(\Delta) =$ `r round(LR.chisq[3],4)` and a p-value of $\mathbb{P}(A>$ `r round(LR.chisq[3],4)` $)=$ `r p.val.chisq[3]` meaning that we have marginal evidence that `TotalCharges` is important to include in the model (given that the other variables are in the model as well). So, depending on the confidence level we select we might include this variable or not (with $\alpha = 0.05$ we would include it, and we wouldn't include it if using $\alpha = 0.01$)

## Effect of change in Monthly payments (10 Points)  

What is the effect of a standard deviation increase in `MonthlyCharges` on the odds of the customer getting churned? Also, calculate the Wald CI for the odds ratio.

We have a model with a shape like:

$$logit(\pi) = \beta_0 + \beta_1 * tenure + \beta_2 * MonthlyCharges + \beta_3 * TotalCharges$$

We know that $OR = \frac{Odds_{x+c}}{Odds_x}$, and in this specific case, for `MonthlyCharges` we'll get the following:

\begin{align*}
    OR &= \frac{Odds_{MonthlyCharges+c}}{Odds_{MonthlyCharges}} \\
    &= \frac{e^{\beta_0 + \beta_1 * tenure + \beta_2 * (MonthlyCharges + c) + \beta_3 * TotalCharges}}{e^{\beta_0 + \beta_1 * tenure + \beta_2 * MonthlyCharges + \beta_3 * TotalCharges}}\\
    &= e^{c \beta_2}
\end{align*}

Now, if we compute the standard deviation for `MonthlyCharges` we have the following:

```{r}
sdMC <- sd(telcom_churn$MonthlyCharges)
sdMC
```
So $\sigma_{MonthlyCharges} =$ `r round(sdMC,2)` and from question 1.6 we know that $\beta_2 =$ `r round(mod.fit.full$coefficients[3],4)`. Therefore, the Odds Ratio for $c = \sigma_{MonthlyCharges}$ is:

```{r}
OR_MC <- exp(sdMC * mod.fit.full$coefficients[3])
OR_MC
```

And we have $OR =  e^{ \sigma_{MonthlyCharges} \beta_2}=$ `r round(OR_MC,4)`, meaning that the odds of a customer churning change by `r round(OR_MC,4)` times for every `r round(sdMC,2)` ($\sigma_{MonthlyCharges}$)increase in `MonthlyCharges`. And the 95% Wald confidence interval for the OR would be:

```{r}
beta2.ci <- confint.default(object = mod.fit.full, parm = "MonthlyCharges", level = 0.95)
OR.ci <- exp(beta2.ci * sdMC)
OR.ci
```


## Confidence Interval for the Probability of Success (10 Points)  
Estimate the 95% profile likelihood confidence interval for the probability of a customer getting churned, considering an average `tenure,` `MonthlyCharges,` and `TotalCharges.`


We first compute all of the averages as follows:

```{r}
avg_ten <- mean(telcom_churn$tenure)
avg_Mon <- mean(telcom_churn$MonthlyCharges)
avg_Tot <- mean(telcom_churn$TotalCharges)
```

Before calculating the profile likelihood CI, ee'll compute a 95% Wald Interval (just for comparison)

```{r}
predict.data <- data.frame(tenure = avg_ten, MonthlyCharges = avg_Mon, TotalCharges = avg_Tot)
linear.pred <- predict(object = mod.fit.full, newdata = predict.data, type = "link", se = TRUE)
CI.lin.pred <- linear.pred$fit + qnorm(p = c(0.05/2, 1 - 0.05/2)) * linear.pred$se
CI.pi <- exp(CI.lin.pred) / (1+exp(CI.lin.pred))
CI.pi
```

Now, to estimate the 95% Profile likelihood interval we'll compute -2log(Lambda) as follows:

```{r}
K <- matrix(data = c(1,avg_ten, avg_Mon, avg_Tot), nrow = 1, ncol = 4)
linear.combo <- mcprofile(object = mod.fit.full, CM = K)
```

Finally creating the 95 % profile LR interval as follows:

```{r}
ci.logit.profile <- confint(object = linear.combo, level = 0.95)
prob.ci <- exp(ci.logit.profile$confint)/ (1+exp(ci.logit.profile$confint))
prob.ci
```

Which is very similar to the Wald interval (because we have a very large sample size).

