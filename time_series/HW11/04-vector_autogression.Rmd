# (12 points) Vector autoregression

```{r load VAR packages, results='hide', message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(feasts)
library(magrittr)
library(patchwork)
library(tsibble)
library(forecast)
library(lmtest)
library(lubridate)
library(fable)
library(tseries)
library(reshape)
library(vars)
```

Annual values for real mortgage credit (RMC), real consumer credit (RCC) and real disposable personal income (RDPI) for the period 1946-2006 are recorded in `./data/mortgage_credit.csv`. 

All of the observations are measured in billions of dollars, after adjustment by the Consumer Price Index (CPI). 

Our goal is to develop a VAR model for these data for the period 1946-2003, and then forecast the last three years, 2004-2006. 


```{r read credit data, message=FALSE}
# Creating tsibble
credit <- read_csv('./data/mortgage_credit.csv')
credit.ts <- credit %>%
 as_tsibble(index = Year)

# Splitting train/test datasets
credit.train <- credit.ts %>% 
  filter_index(~ "2003")
credit.test <- credit.ts %>% 
  filter_index("2004" ~.)
```

## Time series plot

Plot the time-series of real mortgage credit (RMC), real consumer credit (RCC) and real disposable personal income (RDPI)? Do they look stationary?

```{r plot themes}
My_Theme = theme_classic() +
  theme(
  plot.title = element_text(color = "#0099F8",
                            size = 20,
                            face = "bold"),
  plot.subtitle = element_text(color="#969696",
                               size = 14,
                               face = "italic"),
  axis.title = element_text(color = "#969696",
                            size = 12,
                            face = "bold"),
  axis.text = element_text(color = "#969696", size = 11),
  axis.line = element_line(color = "#969696"),
  axis.ticks = element_line(color = "#969696"),
  legend.position = "none"
  )

Double_Theme = theme_classic() +
  theme(
  plot.title = element_text(color = "#0099F8",
                            size = 40,
                            face = "bold"),
  plot.subtitle = element_text(color="#969696",
                            size = 32,
                            face = "italic"),
  axis.title = element_text(color = "#969696",
                            size = 28,
                            face = "bold"),
  axis.text = element_text(color = "#969696", size = 28),
  axis.line = element_line(color = "#969696"),
  axis.ticks = element_line(color = "#969696"),
  )
```


```{r Time series plot}
rmc.plot <- ggplot(
  credit.train, 
  aes(
    x = Year, 
    y = RMC
    )
  ) +
  geom_line(
    size = 0.8,
    color = "cornflowerblue"
    ) +
  labs(
    title = "Real Mortgage Credit (RMC)",
    subtitle = "Yearly Series",
    x = "Year",
    y = "RMC"
    ) +
  My_Theme

rcc.plot <- ggplot(
  credit.train, 
  aes(
    x = Year, 
    y = RCC
    )
  ) +
  geom_line(
    size = 0.8,
    color = "cornflowerblue"
    ) +
  labs(
    title = "Real Consumer Credit (RCC)",
    subtitle = "Yearly Series",
    x = "Year",
    y = "RCC"
    ) +
  My_Theme

rdp.plot <- ggplot(
  credit.train, 
  aes(
    x = Year, 
    y = RDPI
    )
  ) +
  geom_line(
    size = 0.8,
    color = "cornflowerblue"
    ) +
  labs(
    title = "Real Disposable Personal Income (RDPI)",
    subtitle = "Yearly Series",
    x = "Year",
    y = "RDPI"
    ) +
  My_Theme

rmc.plot
rcc.plot
rdp.plot
```

> By just taking a quick look at the 3 plots we can notice that there seems to be a clear trend in them so they don't look stationary and it is likely that we'll need to difference these series to obtain stationary processes.


## Check for the unit root

Plot ACF/PACF and Perform the unit root test on these variables and report the results. Do you reject the null of unit root for them? Is the first differencing necessary? 

```{r ACF PACF and unit root test, fig.width=20, fig.height=7}
# ACF for RMC Original Series
rmc.acf <- ACF(
      credit.train,
      RMC
    ) %>% autoplot() +
    labs(
        title = "Autocorrelation Function",
        subtitle = "Real Mortgage Credit (RMC)",
        x = "lag [Unit = 1Y]",
        y = "Autocorrelation"
    ) + Double_Theme

# PACF for RMC Original Series
rmc.pacf <- PACF(
      credit.train,
      RMC
    ) %>% autoplot() +
    labs(
        title = "Partial Autocorrelation Function",
        subtitle = "Real Mortgage Credit (RMC)",
        x = "lag [Unit = 1Y]",
        y = "Partial Autocorrelation"
    ) + Double_Theme

rmc.acf | rmc.pacf
# Unit Root Test RMC
PP.test(credit.train$RMC)

# ACF for RCC Original Series
rcc.acf <- ACF(
      credit.train,
      RCC
    ) %>% autoplot() +
    labs(
        title = "Autocorrelation Function",
        subtitle = "Real Consumer Credit (RCC)",
        x = "lag [Unit = 1Y]",
        y = "Autocorrelation"
    ) + Double_Theme

# PACF for RCC Original Series
rcc.pacf <- PACF(
      credit.train,
      RCC
    ) %>% autoplot() +
    labs(
        title = "Partial Autocorrelation Function",
        subtitle = "Real Consumer Credit (RCC)",
        x = "lag [Unit = 1Y]",
        y = "Partial Autocorrelation"
    ) + Double_Theme

rcc.acf | rcc.pacf
# Unit Root Test RCC
PP.test(credit.train$RCC)

# ACF for RDPI Original Series
rdp.acf <- ACF(
      credit.train,
      RDPI
    ) %>% autoplot() +
    labs(
        title = "Autocorrelation Function",
        subtitle = "Real Disposable Personal Income (RDPI)",
        x = "lag [Unit = 1Y]",
        y = "Autocorrelation"
    ) + Double_Theme

# PACF for RDPI Original Series
rdp.pacf <- PACF(
      credit.train,
      RDPI
    ) %>% autoplot() +
    labs(
        title = "Partial Autocorrelation Function",
        subtitle = "Real Disposable Personal Income (RDPI)",
        x = "lag [Unit = 1Y]",
        y = "Partial Autocorrelation"
    ) + Double_Theme

rdp.acf | rdp.pacf
# Unit Root Test RDPI
PP.test(credit.train$RDPI)
```

> For all 3 we fail to reject the null ($H_0: \text{non stationary}$) and by looking at the ACFs we can notice that we need to remove the trend, so differencing is indeed necessary. By looking at the PACFs the significant lag is always 1 so First-differencing (meaning lag 1) seems appropriate.


## Determine VAR model

Based on the unit root results transform the variables and determine the lag length of the VAR using the information criteria.

```{r Determine VAR model}
# Creating a ts for differenced variables
diff.df <- credit.train %>%
  mutate(
   RMC.diff = difference(RMC),
   RCC.diff = difference(RCC),
   RDPI.diff = difference(RDPI)
   ) %>%
  filter(Year > "1946") %>% 
  dplyr::select(RMC.diff,RCC.diff, RDPI.diff)

# Testing for Lag Length
VARselect(diff.df, lag.max = 4, type="none")
```

> We'll be using the differenced series, and when evaluating the optimal number of lags, all criteria suggest two lags. So we'll be estimating a VAR(2) model.


## Estimation 

Estimate the selected VAR in previous part and comment on the results.

```{r Estimate VAR}
# Estimating a VAR(2) model
var_diff <- vars::VAR(as.ts(diff.df), p = 2, type = "none")
summary(var_diff)
```

> As previously said we estimated a VAR(2) model, obtaining the following results:

> When estimating differenced RMC, none of the coefficients are statistically significant at even 10% but the ones corresponding to the same variable's lags. Although this is enough to have a high $R^2$ and explain about 88% of the variation in RMC differences.

> For the second equation (estimating differenced RCC), once again its own lags have significant coefficients, and we also find that only RDPI's second lag has marginal significance at 10%. We have a moderately good $R^2$ and explain about 66% of the variation in RCC differences.

> Lastly, when estimating differenced RDPI, we find that its own lags have very significant coefficients, but also RMCs both lags have marginal significance at 10%. We also have a moderately good $R^2$ and we're able to explain about 68% of the variation in RDPI differences.

> We basically can conclude that RMC and RCC are mainly explained by their own lags, but RMCs past lags also have some explaining power to predict RDPI.

## Model diagnostic

Do diagnostic checking of the VAR model.

```{r Model diagnostic}
# Granger-causality
vars::causality(var_diff,cause="RMC.diff")$Granger
vars::causality(var_diff,cause="RCC.diff")$Granger
vars::causality(var_diff,cause="RDPI.diff")$Granger

# Check stability
eigen <- roots(var_diff)
eigen

# No serial correlation
var_diff_test<- serial.test(var_diff, lags.pt = 10)
var_diff_test
```

> To diagnose our model we first conduct a test for Granger-causality, and we find that for all 3 variables we fail to reject the null hypothesis $H_0: \text{variable does not Granger-cause the other two analyzed variables}$, which seems consistent with the previous result.

> Then we find the eigenvalues of the companion matrix. Since all of them are less than one we can conclude that this VAR(2) process is stable.

> Finally we check for autocorrelation in residuals by computing the Portmanteau test for serial correlation where we fail to reject the null hypothesis $H_0: \text{no autocorrelation}$.


## Forecasting

forecast the last three years, 2004-2006.

```{r Forecasting}
# Using the VAR model to predict 3 periods ahead
pred <- predict(var_diff, n.ahead = 3)
pred

# Last data point in the training dataset
last.data <- data.frame(tail(credit.train,1))

# Creating a Dataframe with the predicted differences
diff.pred <- data.frame(
  RMC = pred$fcst$RMC.diff[,1], 
  RCC = pred$fcst$RCC.diff[,1], 
  RDPI = pred$fcst$RDPI.diff[,1],
  Year = 2004:2006
  )
diff.pred <- rbind(last.data, diff.pred)

# Summing to the last value
# To find point estimators for the variables
# Instead of just the differences
final.pred <- data.frame(
  RMC = cumsum(diff.pred$RMC),
  RCC = cumsum(diff.pred$RCC),
  RDPI = cumsum(diff.pred$RDPI),
  Year = diff.pred$Year
)
  
# Keeping only 2004 - 2006
final.pred <- final.pred %>% 
  filter(Year > "2003") %>% 
  as_tsibble(index = Year)
final.pred

# RMC Forecast Plot
rmc.for.plot <- ggplot(
  credit.ts, 
  aes(
    x = Year, 
    y = RMC
    )
  ) +
  geom_line(
    size = 0.5,
    color = "gray",
    alpha = 0.6
    ) +
  labs(
    title = "Real Mortgage Credit (RMC)",
    subtitle = "Yearly Series (gray) VS Forecasted Values (blue)",
    x = "Year",
    y = "RMC"
    ) + autolayer(
      final.pred, 
      .vars = RMC, 
      colour="cornflowerblue",
      size = 1) +
  My_Theme

# RCC Forecast Plot
rcc.for.plot <- ggplot(
  credit.ts, 
  aes(
    x = Year, 
    y = RCC
    )
  ) +
  geom_line(
    size = 0.5,
    color = "gray",
    alpha = 0.6
    ) +
  labs(
    title = "Real Consumer Credit (RCC)",
    subtitle = "Yearly Series (gray) VS Forecasted Values (blue)",
    x = "Year",
    y = "RCC"
    ) + autolayer(
      final.pred, 
      .vars = RCC, 
      colour="cornflowerblue",
      size = 1) +
  My_Theme

# RDPI Forecast Plot
rdp.for.plot <- ggplot(
  credit.ts, 
  aes(
    x = Year, 
    y = RDPI
    )
  ) +
  geom_line(
    size = 0.5,
    color = "gray",
    alpha = 0.6
    ) +
  labs(
    title = "Real Disposable Personal Income (RDPI)",
    subtitle = "Yearly Series (gray) VS Forecasted Values (blue)",
    x = "Year",
    y = "RDPI"
    ) + autolayer(
      final.pred, 
      .vars = RDPI, 
      colour="cornflowerblue",
      size = 1) +
  My_Theme

rmc.for.plot
rcc.for.plot
rdp.for.plot

rmc.ev <- accuracy(final.pred$RMC, credit.test$RMC)
rcc.ev <- accuracy(final.pred$RCC, credit.test$RCC)
rdp.ev <- accuracy(final.pred$RDPI, credit.test$RDPI)
```

> In order to forecast the next 3 years, we proceed to predict the differences for those 3 years and then summing them to the last data point in the training dataset to compute the predicton of the actual values. The results are plotted for all 3 variables and we can see that even when we're mainly using previous lags of the same variable the predicted values make sense with what actually happened. We also have the following accuracy metrics, although we would need more models to compare the model's true efficiency:

| Metric| RMC                   | RCC                   | RDPI                 |
|-------|-----------------------|-----------------------|----------------------|
| ME    | `r round(rmc.ev[1],2)`| `r round(rcc.ev[1],2)`|`r round(rdp.ev[1],2)`|
| RMSE  | `r round(rmc.ev[2],2)`| `r round(rcc.ev[2],2)`|`r round(rdp.ev[2],2)`|
| MAE   | `r round(rmc.ev[3],2)`| `r round(rcc.ev[3],2)`|`r round(rdp.ev[3],2)`|
| MPE   | `r round(rmc.ev[4],2)`| `r round(rcc.ev[4],2)`|`r round(rdp.ev[4],2)`|
| MAPE  | `r round(rmc.ev[5],2)`| `r round(rcc.ev[5],2)`|`r round(rdp.ev[5],2)`|
